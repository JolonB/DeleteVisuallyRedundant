#!/usr/bin/env python3

import argparse
import os
import re

DUPLICATES_FILE = "dups.txt"
FILENAME_REGEX = re.compile("(.+?\.(?:jpe?g|png|gif))(?:\s+|$)", flags=re.IGNORECASE)

parser = argparse.ArgumentParser(
    prog="DeleteVisuallyRedundant",
    description="Delete visually similar images. Retain only the largest and oldest image.",
)
parser.add_argument("filepath")
parser.add_argument(
    "-r",
    "--retain",
    action="store_true",
    help="Retain the dups.txt file generated by findimagedups",
)
parser.add_argument(
    "-d",
    "--dry-run",
    action="store_true",
    help="Print the names of files without actually deleting them",
)


def find_duplicates(filepath):
    # TODO can this be run using Python instead of system calls?
    os.system('findimagedupes -R "{}" > "{}"'.format(filepath, DUPLICATES_FILE))


def delete_all_but_original(filepaths, dry_run=False):
    # TODO add comments!!
    max_size = 0
    max_filepaths = []
    remaining_filepaths = []

    # TODO tidy all of this up
    for filepath in filepaths:
        size = os.stat(filepath).st_size
        if size > max_size:
            max_size = size

    for filepath in filepaths:
        size = os.stat(filepath).st_size

        if size < max_size:
            print("D:", filepath)
            if not dry_run:
                os.remove(filepath)
        elif size == max_size:
            max_filepaths.append(filepath)

    if len(max_filepaths) > 1:
        oldest_modified_time = float("inf")

        for filepath in max_filepaths:
            modified_time = os.stat(filepath).st_mtime

            if modified_time < oldest_modified_time:
                oldest_modified_time = modified_time

        for filepath in max_filepaths:
            modified_time = os.stat(filepath).st_mtime

            if modified_time > oldest_modified_time:
                print("D:", filepath)
                if not dry_run:
                    os.remove(filepath)
            elif modified_time == oldest_modified_time:
                remaining_filepaths.append(filepath)

    # Remove all but one duplicate if any still exist
    for filepath in remaining_filepaths[1:]:
        if not dry_run:
            os.remove(filepath)


def main(filepath, keep_temp_file=False, dry_run=False):
    find_duplicates(filepath)
    with open(DUPLICATES_FILE, "r") as fp:
        for line in fp:
            matches = FILENAME_REGEX.findall(line)

            delete_all_but_original(matches, dry_run=dry_run)

    if not keep_temp_file:
        os.remove(DUPLICATES_FILE)


if __name__ == "__main__":
    args = parser.parse_args()
    filepath = args.filepath
    keep_temp_file = args.retain
    dry_run = args.dry_run

    main(filepath, keep_temp_file=keep_temp_file, dry_run=dry_run)
